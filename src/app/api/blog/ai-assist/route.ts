import { NextRequest, NextResponse } from 'next/server';
import { getUserIdFromRequest } from '@/lib/admin-auth';
import { AgentOrchestrator } from '@/lib/blog/agent-orchestrator';
import { AgentRequest } from '@/lib/blog/agentic-types';
import { getUserAISettings } from '@/lib/ai/settings';
import { taskyDb } from '@/lib/supabase/tasky-db-client';
import { decryptAPIKey } from '@/lib/encryption';

import { auth } from '@/lib/auth-config';

async function getUserTavilyKey(userId: string): Promise<string | null> {
  try {
    const { data: apiKeyRecord, error } = await taskyDb
      .from('user_api_keys')
      .select('key_encrypted, iv, auth_tag')
      .eq('user_id', userId)
      .eq('provider', 'tavily')
      .single();

    if (error || !apiKeyRecord) {
      console.log(`[getUserTavilyKey] No Tavily API key found for user ${userId}`);
      return null;
    }

    const decrypted = decryptAPIKey(
      apiKeyRecord.key_encrypted,
      apiKeyRecord.iv,
      apiKeyRecord.auth_tag
    );

    return decrypted;
  } catch (error) {
    console.error('[getUserTavilyKey] Error fetching Tavily key:', error);
    return null;
  }
}

async function getUserAPIKey(userId: string, provider: string): Promise<string | null> {
  try {
    const { data: apiKeyRecord, error } = await taskyDb
      .from('user_api_keys')
      .select('key_encrypted, iv, auth_tag')
      .eq('user_id', userId)
      .eq('provider', provider)
      .single();

    if (error || !apiKeyRecord) {
      console.log(`[getUserAPIKey] No API key found for user ${userId}, provider ${provider}`);
      return null;
    }

    const decrypted = decryptAPIKey(
      apiKeyRecord.key_encrypted,
      apiKeyRecord.iv,
      apiKeyRecord.auth_tag
    );

    return decrypted;
  } catch (error) {
    console.error(`[getUserAPIKey] Error fetching API key for ${provider}:`, error);
    return null;
  }
}

async function callLLM(
  systemPrompt: string,
  userPrompt: string,
  userId: string,
  overrideProvider?: string,
  overrideModel?: string
): Promise<string> {
  const settings = await getUserAISettings(userId);
  const provider = overrideProvider || settings.defaultProvider;
  let modelId = overrideModel || settings.defaultModel;

  const apiKey = await getUserAPIKey(userId, provider);
  if (!apiKey) {
    throw new Error(`Please configure your ${provider.toUpperCase()} API key in Settings`);
  }

  const { generateText } = await import('ai');
  const { createOpenAI } = await import('@ai-sdk/openai');
  const { createGoogleGenerativeAI } = await import('@ai-sdk/google');
  const { createAnthropic } = await import('@ai-sdk/anthropic');

  async function performAttempt(mId: string, temp: number): Promise<any> {
    console.log(`üîç [Diagnostic] Preparing model call:`, {
      modelId: mId,
      provider,
      temperature: temp,
      maxTokens: settings.maxTokens,
      hasApiKey: !!apiKey,
      apiKeyLength: apiKey?.length,
      systemPromptLength: systemPrompt?.length,
      userPromptLength: userPrompt?.length
    });

    let model: any;
    const sdkKey = apiKey || undefined;
    
    if (!sdkKey) {
      throw new Error(`API key is missing for provider ${provider}. Please configure your API key in Settings.`);
    }

    switch (provider) {
      case 'google':
        model = createGoogleGenerativeAI({ apiKey: sdkKey })(mId);
        break;
      case 'openai':
        model = createOpenAI({ apiKey: sdkKey })(mId);
        break;
      case 'anthropic':
        model = createAnthropic({ apiKey: sdkKey })(mId);
        break;
      case 'openrouter':
      case 'kilo':
        const baseURL = provider === 'kilo' ? 'https://api.kilo.ai/v1' : 'https://openrouter.ai/api/v1';
        model = createOpenAI({ apiKey: sdkKey, baseURL })(mId);
        break;
      default:
        throw new Error(`Unsupported provider: ${provider}`);
    }

    console.log(`üì§ [Request] Calling ${provider}/${mId}...`);
    const result = await generateText({
      model,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt },
      ],
      temperature: temp,
      maxTokens: settings.maxTokens,
    });

    console.log(`üì• [Response] Received from ${provider}/${mId}:`, {
      hasText: !!result?.text,
      textLength: result?.text?.length || 0,
      finishReason: result?.finishReason,
      usage: result?.usage,
      rawResponsePreview: result?.text?.substring(0, 200)
    });

    return result;
  }

  console.log(`ü§ñ [LLM Call] Start: ${provider}/${modelId}`);

  try {
    const response = await performAttempt(modelId, settings.temperature);
    
    if (!response) {
      throw new Error(`Null response from ${provider}/${modelId}. The API call succeeded but returned no data.`);
    }

    if (!response.text || response.text.trim().length === 0) {
      const debugInfo = {
        provider,
        modelId,
        finishReason: response.finishReason,
        usage: response.usage,
        hasText: !!response.text,
        textLength: response.text?.length || 0
      };
      
      console.error(`‚ùå [Empty Response Debug]:`, debugInfo);
      
      // Special handling for OpenRouter free models
      if (provider === 'openrouter' && modelId.includes(':free')) {
        const isUsageInvalid = !response.usage || 
          isNaN(response.usage.totalTokens as number) || 
          response.usage.totalTokens === null;
        
        if (isUsageInvalid) {
          throw new Error(`OpenRouter ÂÖçË¥πÊ®°Âûã [${modelId}] ÂΩìÂâç‰∏çÂèØÁî®„ÄÇ

ÂèØËÉΩÂéüÂõ†:
1. ËØ•ÂÖçË¥πÊ®°ÂûãÁöÑÂÖ®Â±ÄÈÖçÈ¢ùÂ∑≤ËÄóÂ∞Ω
2. Ê®°ÂûãÂ∑≤Ë¢´‰∏ãÊû∂ÊàñÊöÇÊó∂ÂÖ≥Èó≠
3. ÊÇ®ÁöÑ API Key Ëß¶Âèë‰∫ÜÈ¢ëÁéáÈôêÂà∂

‚úÖ Êé®ËçêËß£ÂÜ≥ÊñπÊ°à:
‚Ä¢ ÂàáÊç¢Âà∞ Google Gemini (Á®≥ÂÆö‰∏îÂÖçË¥π): gemini-2.0-flash-exp
‚Ä¢ Êàñ‰ΩøÁî®ÂÖ∂‰ªñ OpenRouter ‰ªòË¥πÊ®°Âûã
‚Ä¢ Ê£ÄÊü• OpenRouter Áä∂ÊÄÅ: https://openrouter.ai/models

üìä ÂΩìÂâçÁä∂ÊÄÅ:
- API ËøûÊé•: ‚úÖ Ê≠£Â∏∏
- ËØ∑Ê±ÇÂ§ÑÁêÜ: ‚ùå Êú™ÊâßË°å (Token ‰ΩøÁî®Èáè‰∏∫ NaN)
- Âª∫ËÆÆ: Á´ãÂç≥ÂàáÊç¢Ê®°Âûã`);
        }
      }
      
      throw new Error(`Ê®°Âûã [${modelId}] ËøîÂõû‰∫ÜÁ©∫ÂÜÖÂÆπ„ÄÇ
Ë∞ÉËØï‰ø°ÊÅØ:
- Êèê‰æõÂïÜ: ${provider}
- ÂÆåÊàêÂéüÂõ†: ${response.finishReason || 'unknown'}
- Token‰ΩøÁî®: ${JSON.stringify(response.usage || 'N/A')}
- ÂèØËÉΩÂéüÂõ†: APIÈÖçÈ¢ùËÄóÂ∞Ω„ÄÅÊ®°ÂûãËøáËΩΩ„ÄÅÊàñËØ∑Ê±ÇË¢´ËøáÊª§

Âª∫ËÆÆ: ËØ∑Ê£ÄÊü• API Key ÊòØÂê¶ÊúâÊïà,ÊàñÂàáÊç¢Âà∞ÂÖ∂‰ªñÊ®°ÂûãÈáçËØï„ÄÇ`);
    }

    console.log(`üìä [LLM Call] Success: ${modelId} (${response.text.length} chars)`);
    return response.text;
  } catch (error: any) {
    console.error(`‚ùå [LLM Final Error] for ${provider}/${modelId}:`, {
      message: error.message,
      stack: error.stack?.split('\n').slice(0, 3),
      cause: error.cause
    });
    
    let friendlyError = error.message;
    if (provider === 'google' && (modelId.includes('gemini-3') || modelId.includes('gemini-1.5') || modelId.includes('gemini-2'))) {
      if (error.message.includes('404') || error.message.includes('not found') || error.message.includes('NOT_FOUND')) {
        friendlyError = `Ê®°Âûã [${modelId}] Âú® Google API ‰∏≠Êú™ÊâæÂà∞„ÄÇ
ÂèØËÉΩÂéüÂõ†:
1. Ê®°Âûã ID ÈîôËØØ (ËØ∑Á°ÆËÆ§ÂÆåÊï¥ ID)
2. ÊÇ®ÁöÑ API Key Êó†ÊùÉËÆøÈóÆÊ≠§Ê®°Âûã
3. ËØ•Ê®°ÂûãÂ∑≤Ë¢´ÂºÉÁî®ÊàñÂêçÁß∞Â∑≤Êõ¥Êîπ

Âª∫ËÆÆ: Â∞ùËØï‰ΩøÁî® 'gemini-2.0-flash-exp' Êàñ 'gemini-1.5-flash'`;
      } else if (error.message.includes('429') || error.message.includes('rate limit') || error.message.includes('quota')) {
        friendlyError = `[${modelId}] API ÈÖçÈ¢ùÂ∑≤Áî®Â∞ΩÊàñËß¶ÂèëÈ¢ëÁéáÈôêÂà∂„ÄÇ
ËØ∑Á®çÂêéÈáçËØï,ÊàñÊ£ÄÊü•ÊÇ®ÁöÑ Google AI Studio ÈÖçÈ¢ùËÆæÁΩÆ„ÄÇ`;
      } else if (error.message.includes('API key')) {
        friendlyError = `Google API Key Êú™ÈÖçÁΩÆÊàñÊó†Êïà„ÄÇ
ËØ∑Âú®ËÆæÁΩÆ‰∏≠ÈÖçÁΩÆÊúâÊïàÁöÑ API Key„ÄÇ
Ëé∑ÂèñÂú∞ÂùÄ: https://makersuite.google.com/app/apikey`;
      }
    }
    
    throw new Error(friendlyError);
  }
}

export async function POST(request: NextRequest) {
  try {
    const session = await auth();

    const userId = getUserIdFromRequest(session?.user?.id, request);
    
    if (!userId) {
      console.error('‚ùå Authentication failed: No user ID found');
      return NextResponse.json(
        { error: 'Unauthorized' },
        { status: 401 }
      );
    }

    const body = await request.json();
    const {
      message,
      conversation_id,
      post_id,
      current_content,
      current_title,
      model,
      provider,
      search_enabled
    } = body;

    if (!message || !post_id || !current_content || !current_title) {
      return NextResponse.json(
        { error: 'Missing required fields: message, post_id, current_content, current_title' },
        { status: 400 }
      );
    }

    const settings = await getUserAISettings(userId);
    
    const targetProvider = provider || settings.defaultProvider;
    
    console.log(`‚öôÔ∏è [AI Settings] Processing request for user ${userId.substring(0, 8)}...`);
    console.log(`   - Target Provider: ${targetProvider} ${provider ? '(User Override)' : '(Default)'}`);
    console.log(`   - Target Model: ${model || settings.defaultModel} ${model ? '(User Override)' : '(Default)'}`);
    console.log(`   - Search Enabled: ${search_enabled !== undefined ? search_enabled : 'Auto (Default)'}`);
    
    const apiKey = await getUserAPIKey(userId, targetProvider);
    
    if (!apiKey) {
      return NextResponse.json(
        { 
          error: 'API key not configured',
          message: `Please configure your ${targetProvider.toUpperCase()} API key in Settings to use the AI Blog Assistant.`,
          requiresSetup: true,
        },
        { status: 400 }
      );
    }

    const tavilyKey = await getUserTavilyKey(userId);
    
    const agentRequest: AgentRequest = {
      message,
      conversation_id,
      post_id,
      current_content,
      current_title,
      user_id: userId,
    };

    const orchestrator = new AgentOrchestrator();
    
    const llmCaller = (systemPrompt: string, userPrompt: string) =>
      callLLM(systemPrompt, userPrompt, userId, provider, model);

    if (tavilyKey && search_enabled !== false) {
      process.env.TAVILY_API_KEY = tavilyKey;
      console.log('üîç [Search] Search enabled and key present');
    } else {
      if (!tavilyKey) {
        console.log('‚ö†Ô∏è [Search] No Tavily API key found. Search disabled.');
      } else {
        console.log('üö´ [Search] Search explicitly disabled by user.');
      }
      delete process.env.TAVILY_API_KEY;
    }

    const response = await orchestrator.execute(agentRequest, llmCaller);

    if (!tavilyKey && response.modification_preview) {
      response.modification_preview.metadata = {
        ...response.modification_preview.metadata,
        searchAvailable: false,
        searchNote: 'Configure Tavily API key in Settings to enable web search for latest information.',
      };
    }

    return NextResponse.json(response);
  } catch (error) {
    console.error('AI Assist API error:', error);
    
    if (error instanceof Error && error.message.includes('API key')) {
      return NextResponse.json(
        {
          error: 'Configuration required',
          message: error.message,
          requiresSetup: true,
        },
        { status: 400 }
      );
    }
    
    return NextResponse.json(
      {
        error: 'Internal server error',
        message: error instanceof Error ? error.message : 'Unknown error',
      },
      { status: 500 }
    );
  }
}
